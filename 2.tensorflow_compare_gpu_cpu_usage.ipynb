{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "major-underwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protective-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-waters",
   "metadata": {},
   "source": [
    "\n",
    "## track performance of machine \n",
    "#CPU: top -p `pgrep \"python\"`  #enter s1 to tell update the stat every second\n",
    "#GPU: watch -n 1 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accessory-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 100x100 matrix product\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation random_uniform/RandomUniform: node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) ]]\n\nCaused by op 'random_uniform/RandomUniform', defined at:\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2887, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2932, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3156, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3347, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9f9a841b0bc0>\", line 53, in <module>\n    experiment()\n  File \"<ipython-input-2-9f9a841b0bc0>\", line 50, in experiment\n    times, sizes = benchmark(devices)\n  File \"<ipython-input-2-9f9a841b0bc0>\", line 15, in benchmark\n    mat1 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 776, in random_uniform\n    name=name)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation random_uniform/RandomUniform: node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation random_uniform/RandomUniform: {{node random_uniform/RandomUniform}}was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[{{node random_uniform/RandomUniform}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9f9a841b0bc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-9f9a841b0bc0>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m   \u001b[1;34m'''Run an experiment that compares CPU and GPU device performance'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m   \u001b[0mdevices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"/gpu:0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m   \u001b[0mtimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m   \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9f9a841b0bc0>\u001b[0m in \u001b[0;36mbenchmark\u001b[1;34m(devices)\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{device} took {round(time_taken,2)}s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation random_uniform/RandomUniform: node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) ]]\n\nCaused by op 'random_uniform/RandomUniform', defined at:\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2887, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2932, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3156, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3347, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9f9a841b0bc0>\", line 53, in <module>\n    experiment()\n  File \"<ipython-input-2-9f9a841b0bc0>\", line 50, in experiment\n    times, sizes = benchmark(devices)\n  File \"<ipython-input-2-9f9a841b0bc0>\", line 15, in benchmark\n    mat1 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 776, in random_uniform\n    name=name)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\dbwab\\.conda\\envs\\ztdl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation random_uniform/RandomUniform: node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[node random_uniform/RandomUniform (defined at <ipython-input-2-9f9a841b0bc0>:15) ]]\n"
     ]
    }
   ],
   "source": [
    "def benchmark(devices):\n",
    "  '''Benchmark each device by computing matrix products'''\n",
    "  times = {device: [] for device in devices}\n",
    "  sizes = range(100, 7000, 500)\n",
    "\n",
    "  for size in sizes:\n",
    "\n",
    "    print(f\"Calculating {size}x{size} matrix product\")\n",
    "\n",
    "    for device in devices:\n",
    "\n",
    "      shape = (size, size)\n",
    "      data_type = tf.float32\n",
    "      with tf.device(device):\n",
    "        mat1 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type)\n",
    "        mat2 = tf.random_uniform(shape=shape, minval=0, maxval=1, dtype=data_type)\n",
    "        matmul = tf.matmul(mat1, mat2)\n",
    "\n",
    "      with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "        start_time = time.time()\n",
    "        result = session.run(matmul)\n",
    "        time_taken = time.time() - start_time\n",
    "        print(f\"{device} took {round(time_taken,2)}s\")\n",
    "        times[device].append(time_taken)\n",
    "\n",
    "  return times, sizes\n",
    "\n",
    "\n",
    "def plot_results(devices, sizes, times):\n",
    "  '''Plot the benchmark results'''\n",
    "  fig, (ax1, ax2) = pyplot.subplots(2, 1, sharex=True)\n",
    " \n",
    "  for device in devices:\n",
    "    ax1.plot(sizes, times[device], 'o-', label=device)\n",
    "  ax1.set_ylabel('Compute Time')\n",
    "  ax1.set_title('Device Compute Time vs. Matrix size')\n",
    "  ax1.legend(devices, loc=2)\n",
    " \n",
    "  ax2.plot(sizes, np.divide(times[devices[1]], times[devices[0]]), 'o-', label=device)\n",
    "  ax2.set_ylabel('GPU Speedup')\n",
    "  ax2.set_xlabel('Matrix size')\n",
    "  ax2.set_title('GPU Speedup vs. Matrix size')\n",
    " \n",
    "  pyplot.show()\n",
    "\n",
    "\n",
    "def experiment():\n",
    "  '''Run an experiment that compares CPU and GPU device performance'''\n",
    "  devices = [\"/gpu:0\", \"/cpu:0\"]\n",
    "  times, sizes = benchmark(devices)\n",
    "  plot_results(devices, sizes, times)\n",
    "\n",
    "experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-checkout",
   "metadata": {},
   "source": [
    "The upper graph shows the time it takes for each device to compute matrix products for different sizes of matrices, with the CPU in orange. The lower graph shows the GPU speedup, which is the ratio of the CPU compute time to the GPU compute time.\n",
    "\n",
    "Here are some conclusions you may have reached:\n",
    "\n",
    "\n",
    "#The CPU time grows proportional to the size of the matrix squared or cubed. That is, doubling the matrix size results in a 4X to 8X increase in compute time. This follows the growth in the number of computations required to calculate matrix products of different sizesThe GPU time grows almost linearly with the size of the matrix for the sizes used in the experiment. That is doubling the size doubles the time. This indicates that the GPU hasn't reached capacity. It is able to add more compute cores to complete the computation in much shorter times than a CPU.\n",
    "\n",
    "The compute time for matrices of size less than 1000 is similar for GPU and CPU. Sometimes the CPU performs better than GPU for these small sizes. Transfering results from GPU to CPU and initializing GPU programs create some overhead in using a GPU. In general, GPUs excel for large-scale problems.The speedup increases with the matrix size. The maximum reached is around 20X. A 20X speedup can mean a compute job finishing in 1 day on CPU, or in 1 hour on GPU. \n",
    "\n",
    "For larger problems, GPUs can offer speedups in the hundreds.\n",
    "\n",
    "In this Lab Step, you analyzed the results of the experiment and gained an understanding of when GPUs can offer substantial improvements and when they are overkill. For a complete comparison you need to consider the cost of running GPU instances to running CPU-only instances. Usually, if you have problems large enough to be compute-bound, the price increase of using GPUs is significantly less than the speedup achieved by using GPUs. This results in a reduced overall price.For very large problems, you can utilize multiple GPUs in a cluster. \n",
    "\n",
    "AWS provides a machine learning CloudFormation template to help with setting up an auto-scaled cluster of GPUs for machine learning tasks. Challenge (Optional)If you have time remaining in your Lab Session, try to modify the code to see what size of matrix causes the GPU to become compute-bound. Observe how high the temperature reaches while running in a compute-bound state for an extended period.  Also, see what the maximum speedup you can achieve by using the GPU is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
